{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dOaYbAh8flk"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚òÄÔ∏è Solar Panel & Boiler Detection in Madagascar - Satellite & Drone Imagery Challenge\n",
    "\n",
    "## üìú Competition Overview\n",
    "\n",
    "Access to reliable and sustainable energy is a critical issue in Madagascar and across Africa, where many communities either lack electricity or rely on costly, environmentally harmful energy sources. Solar technology offers a promising alternative ‚Äî but identifying and tracking the adoption of solar panels and boilers over large, remote areas remains a major challenge.\n",
    "\n",
    "The goal of this competition is to develop a **machine learning model** capable of **detecting and counting** solar panels and solar boilers in satellite and drone imagery of Madagascar.\n",
    "\n",
    "A robust detection system has important real-world applications, including:\n",
    "- Supporting governments and NGOs with energy planning and policy\n",
    "- Monitoring the impact of renewable energy programs\n",
    "- Optimizing resource allocation for electrification efforts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:20.651853Z",
     "iopub.status.busy": "2025-02-21T20:32:20.651526Z",
     "iopub.status.idle": "2025-02-21T20:32:20.879920Z",
     "shell.execute_reply": "2025-02-21T20:32:20.878713Z",
     "shell.execute_reply.started": "2025-02-21T20:32:20.651816Z"
    },
    "id": "anJiNQwP6jq5",
    "outputId": "7eed6c1a-fb25-47f9-afd6-f70a886dc94b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 21 20:32:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   42C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "#papapap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Library Imports\n",
    "\n",
    "We begin by importing all necessary libraries for the project, including:\n",
    "\n",
    "- **PyTorch** for deep learning model development\n",
    "- **Albumentations** for powerful image augmentations\n",
    "- **TIMM** for easy access to pretrained image models\n",
    "- **Pandas** and **NumPy** for data handling\n",
    "- **OpenCV** and **PIL** for image processing\n",
    "- **Scikit-learn** for cross-validation strategies\n",
    "- **TQDM** for progress visualization during training\n",
    "\n",
    "These tools form the foundation of the modeling pipeline for solar panel and boiler detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:20.881820Z",
     "iopub.status.busy": "2025-02-21T20:32:20.881538Z",
     "iopub.status.idle": "2025-02-21T20:32:35.473099Z",
     "shell.execute_reply": "2025-02-21T20:32:35.472136Z",
     "shell.execute_reply.started": "2025-02-21T20:32:20.881796Z"
    },
    "id": "Y5T_1zXS9HRb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a8747c79-80d9-4263-fcd2-a410ab24388e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bi_jqci98hjS"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Load Training Data\n",
    "\n",
    "We load the provided training dataset, which contains:\n",
    "- Image identifiers\n",
    "- Corresponding labels (number of solar panels and boilers)\n",
    "\n",
    "This structured data will be used to train and validate our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.530202Z",
     "iopub.status.busy": "2025-02-21T20:32:35.529838Z",
     "iopub.status.idle": "2025-02-21T20:32:35.572163Z",
     "shell.execute_reply": "2025-02-21T20:32:35.571004Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.530168Z"
    },
    "id": "saWCS23p2EEK",
    "outputId": "c160cee4-db1c-4950-c8ce-4b1a3fcaaf27",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read in the training dataset\n",
    "train = pd.read_csv(\"/kaggle/input/lacuna-solar-survey-challenge/Train.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Preprocessing: Dataset Structuring\n",
    "\n",
    "We perform preprocessing steps to better structure the dataset for model training:\n",
    "\n",
    "- Create mappers for `placement` and `img_origin` information linked to each image ID\n",
    "- Aggregate the `boil_nbr` and `pan_nbr` counts per unique image\n",
    "- Merge back additional metadata (`placement` and `img_origin`)\n",
    "- Generate the full file path for each image\n",
    "\n",
    "This prepares a clean and enriched dataframe for further modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.574606Z",
     "iopub.status.busy": "2025-02-21T20:32:35.574205Z",
     "iopub.status.idle": "2025-02-21T20:32:35.649467Z",
     "shell.execute_reply": "2025-02-21T20:32:35.648348Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.574579Z"
    },
    "id": "5DF3hPzM2wIG",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>boil_nbr</th>\n",
       "      <th>pan_nbr</th>\n",
       "      <th>img_origin</th>\n",
       "      <th>placement</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID0I1tHW</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ID0POc2HN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ID0RNQgs4Y1a7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ID0YWEiDPjmAfA50E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ID0g0Yd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>IDzZw0Ot8e05Xu</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>IDzaUuik1u5aOQt9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>IDzj0TllxhxN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>IDzpcgPa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>IDzt0z6lQC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  boil_nbr  pan_nbr img_origin  placement  \\\n",
       "19             ID0I1tHW         1        0          S  S-unknown   \n",
       "30            ID0POc2HN         1        0          S  S-unknown   \n",
       "32        ID0RNQgs4Y1a7         1        0          S  S-unknown   \n",
       "39    ID0YWEiDPjmAfA50E         1        0          S  S-unknown   \n",
       "44              ID0g0Yd         1        0          S  S-unknown   \n",
       "...                 ...       ...      ...        ...        ...   \n",
       "3287     IDzZw0Ot8e05Xu         1        0          S  S-unknown   \n",
       "3288   IDzaUuik1u5aOQt9         2        0          S  S-unknown   \n",
       "3295       IDzj0TllxhxN         1        0          S  S-unknown   \n",
       "3303           IDzpcgPa         1        0          S  S-unknown   \n",
       "3307         IDzt0z6lQC         1        0          S  S-unknown   \n",
       "\n",
       "                                                   path  \n",
       "19    /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "30    /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "32    /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "39    /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "44    /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "...                                                 ...  \n",
       "3287  /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "3288  /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "3295  /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "3303  /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "3307  /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "\n",
       "[489 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a placement mapper\n",
    "placement_mapper = train[[\"ID\", \"placement\"]].drop_duplicates().set_index(\"ID\").to_dict()\n",
    "# Create a \"img_origin\" mapper\n",
    "img_origin_mapper = train[[\"ID\", \"img_origin\"]].drop_duplicates().set_index(\"ID\").to_dict()\n",
    "\n",
    "# Group by \"ID\" and sum up boil_nb, pan_nbr\n",
    "train_df = train.groupby(\"ID\").sum().reset_index()[[\"ID\", \"boil_nbr\", \"pan_nbr\"]]\n",
    "\n",
    "# Map img_origin and placement\n",
    "train_df[\"img_origin\"] = train_df[\"ID\"].map(img_origin_mapper[\"img_origin\"])\n",
    "train_df[\"placement\"] = train_df[\"ID\"].map(placement_mapper[\"placement\"])\n",
    "train_df\n",
    "# Create path column\n",
    "train_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + train_df[\"ID\"] + \".jpg\"\n",
    "train_df[train_df['boil_nbr']!=0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.651598Z",
     "iopub.status.busy": "2025-02-21T20:32:35.651223Z",
     "iopub.status.idle": "2025-02-21T20:32:35.662522Z",
     "shell.execute_reply": "2025-02-21T20:32:35.661353Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.651572Z"
    },
    "id": "ULcbkzcQ-T86",
    "outputId": "59ca52bc-f36e-41ec-9590-a913ea89fd88",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>boil_nbr</th>\n",
       "      <th>pan_nbr</th>\n",
       "      <th>img_origin</th>\n",
       "      <th>placement</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00rw8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>roof</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID014O6EC7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>roof</td>\n",
       "      <td>/kaggle/input/lacuna-solar-survey-challenge/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  boil_nbr  pan_nbr img_origin placement  \\\n",
       "0     ID00rw8         0        2          D      roof   \n",
       "1  ID014O6EC7         0        1          D      roof   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/lacuna-solar-survey-challenge/im...  \n",
       "1  /kaggle/input/lacuna-solar-survey-challenge/im...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Cross-Validation Strategy: Stratified K-Fold\n",
    "\n",
    "To ensure balanced distribution of multi-label targets across folds, we implement **Stratified K-Fold** cross-validation:\n",
    "\n",
    "- Create a `stratify_label` by summing `boil_nbr` and `pan_nbr` for each sample\n",
    "- Use **7 folds** with shuffling and a fixed random seed for reproducibility\n",
    "- Assign a `fold` index to each sample for organized training and validation splits\n",
    "\n",
    "This method helps maintain class balance during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.664003Z",
     "iopub.status.busy": "2025-02-21T20:32:35.663680Z",
     "iopub.status.idle": "2025-02-21T20:32:35.697968Z",
     "shell.execute_reply": "2025-02-21T20:32:35.696826Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.663972Z"
    },
    "id": "HKG3kLmc3U0j",
    "outputId": "dec2c167-1473-4413-c7c6-68fc5b9ef7a8",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=7.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Stratified KFold based on multi-label targets\n",
    "train_df[\"stratify_label\"] = train_df[[\"boil_nbr\", \"pan_nbr\"]].sum(axis=1)\n",
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "train_df[\"fold\"] = -1\n",
    "for fold, (_, valid_idx) in enumerate(skf.split(train_df, train_df[\"stratify_label\"])):\n",
    "    train_df.loc[valid_idx, \"fold\"] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Data Augmentation Strategies\n",
    "\n",
    "To improve the model‚Äôs robustness and prevent overfitting, we apply a combination of **Albumentations** and **PyTorch** data augmentations:\n",
    "\n",
    "### Custom Transformations:\n",
    "- **RandomSharpen**: Randomly increases image sharpness\n",
    "- **RandomBlur**: Randomly applies Gaussian blur\n",
    "\n",
    "### Albumentations Transforms (for training and testing):\n",
    "- Resizing, flipping, brightness/contrast adjustment\n",
    "- Shift, scale, rotate, elastic, and grid distortions\n",
    "- Normalization and conversion to tensor\n",
    "\n",
    "### PyTorch Transforms (for training and validation):\n",
    "- Resize to InceptionV3‚Äôs input size (299√ó299)\n",
    "- Random horizontal flip, sharpening, blurring\n",
    "- Normalization following ImageNet statistics\n",
    "\n",
    "These augmentations simulate real-world conditions and improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.707767Z",
     "iopub.status.busy": "2025-02-21T20:32:35.707407Z",
     "iopub.status.idle": "2025-02-21T20:32:35.740150Z",
     "shell.execute_reply": "2025-02-21T20:32:35.739108Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.707731Z"
    },
    "id": "Wn5YdAa6DQru",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomSharpen:\n",
    "    def __init__(self, probability=0.5):\n",
    "        self.probability = probability\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.probability:\n",
    "            enhancer = ImageEnhance.Sharpness(img)\n",
    "            img = enhancer.enhance(random.uniform(1.5, 2.0))  # Randomly increase sharpness\n",
    "        return img\n",
    "\n",
    "class RandomBlur:\n",
    "    def __init__(self, probability=0.5):\n",
    "        self.probability = probability\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.probability:\n",
    "            img = np.array(img)\n",
    "            ksize = random.choice([3, 5])  # Randomly choose kernel size\n",
    "            img = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "            img = Image.fromarray(img)\n",
    "        return img\n",
    "\n",
    "# Define Albumentations transformations\n",
    "albu_train_transforms = A.Compose([\n",
    "    A.Resize(256, 256),  # Resize the image to 256x256\n",
    "    A.HorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Randomly adjust brightness and contrast with 20% probability\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),  \n",
    "    # Randomly shift, scale, and rotate the image\n",
    "    A.GridDistortion(p=0.2),  # Apply grid distortion with 20% probability\n",
    "    A.ElasticTransform(p=0.2),  # Apply elastic transform with 20% probability\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
    "    ToTensorV2()  # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "albu_test_transforms = A.Compose([\n",
    "    A.Resize(256, 256),  # Resize the image to 256x256\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
    "    ToTensorV2()  # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "# Define PyTorch transformations\n",
    "torch_train_transforms = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    RandomSharpen(probability=0.5),\n",
    "    RandomBlur(probability=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "torch_valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # InceptionV3 expects 299x299 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Combined Albumentations and PyTorch Transformations\n",
    "\n",
    "We define a custom **CombinedTransform** class to seamlessly merge **Albumentations** and **PyTorch** transformations in a single pipeline:\n",
    "\n",
    "- First, apply powerful augmentations from Albumentations (e.g., resizing, distortions).\n",
    "- Then, convert the augmented image back to a **PIL** format.\n",
    "- Finally, apply additional PyTorch transformations (e.g., random blur, sharpening, normalization).\n",
    "\n",
    "### Purpose:\n",
    "This approach leverages the strengths of both libraries, ensuring rich, diverse augmentations while maintaining compatibility with PyTorch DataLoaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.802358Z",
     "iopub.status.busy": "2025-02-21T20:32:35.802030Z",
     "iopub.status.idle": "2025-02-21T20:32:35.829750Z",
     "shell.execute_reply": "2025-02-21T20:32:35.828756Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.802320Z"
    },
    "id": "urT-xV7X_tKB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom transformation class to combine Albumentations and PyTorch transformations\n",
    "class CombinedTransform:\n",
    "    def __init__(self, albu_transform, torch_transform):\n",
    "        self.albu_transform = albu_transform\n",
    "        self.torch_transform = torch_transform\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # Apply Albumentations transformations\n",
    "        image = np.array(image)\n",
    "        augmented = self.albu_transform(image=image)\n",
    "        image = augmented['image']\n",
    "        \n",
    "        # Convert back to PIL image for PyTorch transformations\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        # Apply PyTorch transformations\n",
    "        image = self.torch_transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Combine transformations\n",
    "train_transforms = CombinedTransform(albu_train_transforms, torch_train_transforms)\n",
    "valid_transforms = CombinedTransform(albu_test_transforms, torch_valid_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Dataset, Early Stopping, and Model Architecture\n",
    "\n",
    "This section builds the essential backbone for model training:\n",
    "\n",
    "### üì¶ Custom Dataset Class: `SolarPanelDataset`\n",
    "- Loads images based on paths in the dataframe.\n",
    "- Applies the combined Albumentations and PyTorch transformations.\n",
    "- Returns either:\n",
    "  - Image and target (boiler and panel counts) for training.\n",
    "  - Image only for inference.\n",
    "\n",
    "### ‚è≥ Early Stopping Strategy\n",
    "- A custom **EarlyStopping** class monitors validation loss.\n",
    "- Stops training early if no improvement is seen after a defined patience.\n",
    "- Saves the best model checkpoint automatically.\n",
    "\n",
    "### üß† Model Architecture: `InceptionRegressor`\n",
    "- Built upon a **pretrained InceptionV3** model using **timm**.\n",
    "- Modifies the final fully connected layer to output two values:\n",
    "  - **Boiler count** and **Solar panel count**.\n",
    "\n",
    "This design ensures an efficient and stable training process focused on both predictive performance and overfitting prevention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T20:32:35.802358Z",
     "iopub.status.busy": "2025-02-21T20:32:35.802030Z",
     "iopub.status.idle": "2025-02-21T20:32:35.829750Z",
     "shell.execute_reply": "2025-02-21T20:32:35.828756Z",
     "shell.execute_reply.started": "2025-02-21T20:32:35.802320Z"
    },
    "id": "urT-xV7X_tKB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class SolarPanelDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, to_train=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.to_train = to_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.to_train:\n",
    "            target = torch.tensor([row[\"boil_nbr\"], row[\"pan_nbr\"]], dtype=torch.float32)\n",
    "            return image, target\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.best_score:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "import timm\n",
    "import torch.optim as optim\n",
    "\n",
    "class InceptionRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionRegressor, self).__init__()\n",
    "        self.model = timm.create_model(\"inception_v3\", pretrained=True)\n",
    "        # Replace the last fully connected layer\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Model Training Setup and Data Preparation\n",
    "\n",
    "This section sets up the environment for training the solar panel and boiler detection model using an InceptionV3 backbone.\n",
    "\n",
    "### üõ† Model and Training Configuration\n",
    "- **Model**: `InceptionRegressor` based on a pretrained `inception_v3` model from `timm`.\n",
    "- **Loss Function**: L1 Loss (`nn.L1Loss`) for robust regression performance.\n",
    "- **Optimizer**: Adam optimizer with an initial learning rate of `1e-4`.\n",
    "- **Learning Rate Scheduler**: Reduces the learning rate by a factor of 0.1 if the validation loss plateaus for 5 epochs.\n",
    "- **Early Stopping**: Stops training if validation loss does not improve for 10 consecutive epochs.\n",
    "- **Device**: Automatically selects GPU if available, otherwise CPU.\n",
    "- **Logging**: TensorBoard `SummaryWriter` is initialized for monitoring training progress.\n",
    "\n",
    "### üì¶ Dataloader Preparation\n",
    "- **Stratified K-Fold** is used for creating training and validation splits based on the sum of boiler and panel counts.\n",
    "- **Fold Selection**: Fold 0 is used for validation; the remaining folds are used for training.\n",
    "- **Datasets**: \n",
    "  - `SolarPanelDataset` instances apply a combination of Albumentations and TorchVision transformations.\n",
    "- **DataLoaders**: \n",
    "  - **Training**: Batches of 32 images with shuffling enabled.\n",
    "  - **Validation**: Batches of 32 images without shuffling.\n",
    "  - **Parallelism**: Utilizes all available CPU cores for efficient data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T20:35:21.758718Z",
     "iopub.status.busy": "2025-02-21T20:35:21.758017Z",
     "iopub.status.idle": "2025-02-21T20:35:21.769400Z",
     "shell.execute_reply": "2025-02-21T20:35:21.768229Z",
     "shell.execute_reply.started": "2025-02-21T20:35:21.758681Z"
    },
    "id": "5zg6m_dc9Va7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Training Setup\n",
    "model = InceptionRegressor().cuda()\n",
    "criterion = nn.L1Loss()  # MAE Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "best_model_path = \"best_model.pth\"\n",
    "num_epochs = 50\n",
    "best_loss = float(\"inf\")\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Prepare Dataloaders\n",
    "fold = 0  # Change fold index as needed\n",
    "train_data = train_df[train_df[\"fold\"] != fold].reset_index(drop=True)\n",
    "valid_data = train_df[train_df[\"fold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "dataset_train = SolarPanelDataset(train_data, transform=train_transforms)\n",
    "dataset_valid = SolarPanelDataset(valid_data, transform=valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "valid_loader = DataLoader(dataset_valid, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T20:35:22.679335Z",
     "iopub.status.busy": "2025-02-21T20:35:22.678951Z",
     "iopub.status.idle": "2025-02-21T20:35:22.925181Z",
     "shell.execute_reply": "2025-02-21T20:35:22.924362Z",
     "shell.execute_reply.started": "2025-02-21T20:35:22.679304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully: (3956, 5280, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"/kaggle/input/lacuna-solar-survey-challenge/images/ID00rw8.jpg\")\n",
    "if image is not None:\n",
    "    print(\"Image loaded successfully:\", image.shape)\n",
    "else:\n",
    "    print(\"Failed to load image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Model Training Loop\n",
    "\n",
    "The model is trained over a maximum of 50 epochs with early stopping and dynamic learning rate adjustment to optimize performance.\n",
    "\n",
    "### üîÑ Training and Validation Steps\n",
    "- **Training Phase**:\n",
    "  - Model set to training mode (`model.train()`).\n",
    "  - For each batch:\n",
    "    - Inputs and targets are loaded onto the device.\n",
    "    - Forward pass is performed.\n",
    "    - L1 loss is computed.\n",
    "    - Gradients are backpropagated, and the optimizer updates the model parameters.\n",
    "- **Validation Phase**:\n",
    "  - Model set to evaluation mode (`model.eval()`).\n",
    "  - No gradient computations (`torch.no_grad()`).\n",
    "  - Loss is computed for validation data.\n",
    "\n",
    "### üìà Monitoring and Optimization\n",
    "- **Loss Tracking**:\n",
    "  - Both training and validation losses are averaged and logged each epoch.\n",
    "- **Early Stopping**:\n",
    "  - Stops training if no improvement is observed for 10 consecutive validation evaluations.\n",
    "- **Learning Rate Scheduling**:\n",
    "  - Reduces learning rate when the validation loss plateaus to fine-tune learning.\n",
    "- **TensorBoard Logging**:\n",
    "  - Loss curves for both training and validation phases are recorded using TensorBoard's `SummaryWriter`.\n",
    "\n",
    "### üìù Notes\n",
    "- The best model is saved automatically during training whenever a new lowest validation loss is achieved.\n",
    "- If early stopping criteria are met, the training process halts early to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "execution_failed": "2025-02-22T13:48:59.782Z",
     "iopub.execute_input": "2025-02-21T20:37:39.770408Z",
     "iopub.status.busy": "2025-02-21T20:37:39.770008Z"
    },
    "id": "D5gV2mYT_zFy",
    "outputId": "0fb50c5a-93c1-46ee-b1fe-ed04556c821d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:32<00:00,  3.06s/it]\n",
      "Epoch 1/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [02:10<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.5297, Val Loss: 2.5917\n",
      "Validation loss decreased (-2.591667 --> 2.591667).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:31<00:00,  3.05s/it]\n",
      "Epoch 2/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:44<00:00,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 2.4085, Val Loss: 2.5452\n",
      "Validation loss decreased (-2.545186 --> 2.545186).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:21<00:00,  2.93s/it]\n",
      "Epoch 3/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:39<00:00,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 2.3204, Val Loss: 2.3424\n",
      "Validation loss decreased (-2.342386 --> 2.342386).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:21<00:00,  2.94s/it]\n",
      "Epoch 4/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:42<00:00,  6.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 2.2414, Val Loss: 2.3115\n",
      "Validation loss decreased (-2.311466 --> 2.311466).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:25<00:00,  2.99s/it]\n",
      "Epoch 5/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:44<00:00,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 2.2329, Val Loss: 2.3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:27<00:00,  3.00s/it]\n",
      "Epoch 6/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:45<00:00,  7.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 2.1061, Val Loss: 2.3249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:26<00:00,  2.99s/it]\n",
      "Epoch 7/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:43<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 2.0905, Val Loss: 2.0902\n",
      "Validation loss decreased (-2.090153 --> 2.090153).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:22<00:00,  2.95s/it]\n",
      "Epoch 8/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:45<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 2.0729, Val Loss: 2.1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:27<00:00,  3.01s/it]\n",
      "Epoch 9/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:46<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 2.0843, Val Loss: 2.3030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:27<00:00,  3.00s/it]\n",
      "Epoch 10/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:45<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 1.9804, Val Loss: 2.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:27<00:00,  3.01s/it]\n",
      "Epoch 11/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:46<00:00,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 1.9625, Val Loss: 2.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:26<00:00,  2.99s/it]\n",
      "Epoch 12/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:44<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 1.9380, Val Loss: 2.0857\n",
      "Validation loss decreased (-2.085653 --> 2.085653).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:26<00:00,  3.00s/it]\n",
      "Epoch 13/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:45<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 1.9990, Val Loss: 2.1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:29<00:00,  3.02s/it]\n",
      "Epoch 14/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:44<00:00,  6.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 1.8853, Val Loss: 2.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:21<00:00,  2.94s/it]\n",
      "Epoch 15/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:43<00:00,  6.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 1.8964, Val Loss: 2.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:21<00:00,  2.94s/it]\n",
      "Epoch 16/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:42<00:00,  6.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 1.7932, Val Loss: 2.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:22<00:00,  2.95s/it]\n",
      "Epoch 17/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:45<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 1.7698, Val Loss: 2.2128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [04:26<00:00,  2.99s/it]\n",
      "Epoch 18/50 - Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:45<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 1.7957, Val Loss: 2.2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Training:  10%|‚ñà         | 9/89 [00:37<05:53,  4.42s/it]"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "best_loss = float(\"inf\")\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Average Loss\n",
    "    train_loss = epoch_loss / len(train_loader)\n",
    "    val_loss /= len(valid_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save Best Model\n",
    "    early_stopping(val_loss, model, best_model_path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation\n",
    "\n",
    "After training, the best-performing model (based on validation loss) is loaded and evaluated on the validation dataset.\n",
    "\n",
    "### üîç Steps Performed\n",
    "- **Model Loading**:\n",
    "  - The model's parameters are restored from the saved checkpoint (`best_model.pth`).\n",
    "- **Prediction**:\n",
    "  - The model is set to evaluation mode.\n",
    "  - Forward passes are performed on the validation set without updating gradients.\n",
    "  - Predictions and true labels are collected for evaluation.\n",
    "- **Evaluation Metric**:\n",
    "  - The performance is assessed using **Mean Absolute Error (MAE)**, providing a straightforward interpretation of the model's average prediction error.\n",
    "\n",
    "### üìà Output\n",
    "- Displays the final **Validation MAE**, indicating the average number of panels/boilers the model is off by.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-02-21T20:32:38.002442Z",
     "iopub.status.idle": "2025-02-21T20:32:38.002743Z",
     "shell.execute_reply": "2025-02-21T20:32:38.002598Z"
    },
    "id": "QKQh0lfnPwqq",
    "outputId": "0e820462-63b0-406d-bf14-ca0fb8050633",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Best Model\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Predict on Validation Set\n",
    "preds = []\n",
    "true_vals = []\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(valid_loader, desc=\"Predicting on Validation Set\"):\n",
    "        images = images.cuda()\n",
    "        outputs = model(images).cpu().numpy()\n",
    "        preds.append(outputs)\n",
    "        true_vals.append(targets.numpy())\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Evaluate using MAE\n",
    "mae = mean_absolute_error(true_vals, preds)\n",
    "print(f\"Validation MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Generating Test Predictions and Submission\n",
    "\n",
    "After validating the model, predictions are generated for the unseen **test set**.\n",
    "\n",
    "### üõ†Ô∏è Steps Performed\n",
    "- **Prepare Test Data**:\n",
    "  - Test images are read and preprocessed using the validation transforms.\n",
    "- **Model Inference**:\n",
    "  - The trained model predicts the number of boilers and panels for each test image.\n",
    "- **Submission File Creation**:\n",
    "  - Predictions are formatted according to the competition submission rules:\n",
    "    - For each image ID, two rows are created: one for boilers (`_boil`) and one for panels (`_pan`).\n",
    "  - Predicted values are clipped between **0** and **1000** to ensure reasonable outputs.\n",
    "- **Saving Submission**:\n",
    "  - A `Submission.csv` file is generated and saved for final submission.\n",
    "\n",
    "### üìÑ Output\n",
    "- `Submission.csv` containing model predictions ready for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-02-21T20:32:38.004698Z",
     "iopub.status.idle": "2025-02-21T20:32:38.005053Z",
     "shell.execute_reply": "2025-02-21T20:32:38.004895Z"
    },
    "id": "cepD5bBiP2Fz",
    "outputId": "e833f539-2ec0-447f-e68d-1aea953c5e93",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predict on Test Set\n",
    "test_df = pd.read_csv(\"/kaggle/input/lacuna-solar-survey-challenge/Test.csv\")\n",
    "\n",
    "test_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + test_df[\"ID\"] + \".jpg\"\n",
    "\n",
    "dataset_test = SolarPanelDataset(test_df, transform=valid_transforms, to_train=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"Predicting on Test Set\"):\n",
    "        images = images.cuda()\n",
    "        outputs = model(images).cpu().numpy()\n",
    "        test_preds.append(outputs)\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "\n",
    "# Create Sample Submission\n",
    "submission = pd.DataFrame()\n",
    "submission[\"ID\"] = np.repeat(test_df[\"ID\"].values, 2)\n",
    "submission[\"ID\"] = submission[\"ID\"] + np.tile([\"_boil\", \"_pan\"], len(test_df))\n",
    "submission[\"Target\"] = test_preds.flatten().clip(0,1000)\n",
    "\n",
    "# Save Submission\n",
    "submission.to_csv(\"Submission.csv\", index=False)\n",
    "print(\"Submission saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6691299,
     "sourceId": 10783793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b074c585dd5460f892711429f1d78aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3db63fd099ba4a2a8d3ffcaa147b6011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f26197afbe3469cb2d27ea32f7257ee",
      "max": 31471874,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d026f74db1264804b09f4b93da7bf720",
      "value": 31471874
     }
    },
    "5a5479ef19af4814b4a227ea44ffd90a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e52204a5e84f419994c7017fc2b3bbf8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0b074c585dd5460f892711429f1d78aa",
      "value": "‚Äá31.5M/31.5M‚Äá[00:00&lt;00:00,‚Äá56.8MB/s]"
     }
    },
    "5ca7b048742c49e986dd8e30727367a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60f4949511b44ae499946129cee86819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "654c794449bd42378ad0ff1ba20a3842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77ac0e5761554e789f001c1045129ea8",
       "IPY_MODEL_3db63fd099ba4a2a8d3ffcaa147b6011",
       "IPY_MODEL_5a5479ef19af4814b4a227ea44ffd90a"
      ],
      "layout": "IPY_MODEL_60f4949511b44ae499946129cee86819"
     }
    },
    "69079a20dea64e91885053bf2cc54a4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ac0e5761554e789f001c1045129ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69079a20dea64e91885053bf2cc54a4c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5ca7b048742c49e986dd8e30727367a7",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "8f26197afbe3469cb2d27ea32f7257ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d026f74db1264804b09f4b93da7bf720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e52204a5e84f419994c7017fc2b3bbf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
